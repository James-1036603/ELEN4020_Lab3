Download


Source

PDF
Actions

   Copy Project
   Word Count
Sync

   Dropbox
   Git
   GitHub
Settings

Compiler

Main document

Spell check

Auto-complete

Auto-close Brackets

Code check

Editor theme

Overall theme

Keybindings

Font Size

Font Family

Line Height

PDF Viewer

Hotkeys

   Show Hotkeys
Menu
DICS Lab 3
Review
Share
Submit
History
Chat
 IEEEtran.cls
 main.tex
 outputDemon1.png
 outputDemon2.png
 references.bib
Editor mode.SourceRich Text

91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
Phoenix is a shared-memory implementation of the MapReduce model written in C++ 
\cite{mapreduce}. The functionality provided by the environment is used to implement 
MapReduce using the discussed algorithms. The \texttt{split} function is used to split the 
text file contents between a number of threads. This ideal for processing large datasets as 
is the case with \textit{File2ForLab3.txt}. The \texttt{map} function is overloaded to 
define the required output of each mapping, in this case key-value pairs representing a word 
and its count are required. The combiner collects the counts of a specific word into a 
container and adds them. The running times of each algorithm are illustrated in Table 
\ref{tbl: cc-risk table}. Running times are for both using \textit{File1ForLab3.txt} and 
\textit{File2ForLab3.txt} as an input dataset. 
\begin{table}[!ht] \label{table}
\centering
\caption{Table indicating algorithm runtimes per text file}
\label{tbl: cc-risk table}
\begin{tabular}{|1|1|1|1|1|}
\hline
\textbf{File} & \textbf{Word count duration (ms)} & \textbf{Top 10 duration (ms)} & 
\textbf{Top 20 duration (ms)}                           \\ \hline
\textit{File1ForLab3.txt}             & 317.8  & 0.019 & 0.039                  \\ \hline
\textit{File2ForLab3.txt}          & 10.312   & 0.01  & 0.025   \\ \hline
\end{tabular}
\end{table}
It is evident that the running times of the word count algorithm with 
\textit{File1ForLab3.txt} as an input are shorter than those for \textit{File2ForLab3.txt}. 
This is as expected as \textit{File2ForLab3.txt} is the larger of the two text files 
therefore more data is required to be split, mapped and then combined. The top 10 and 20 
queries are relatively similar. This is valid as the algorithm simply selects the top 10 and 
20 of an already sorted word count. Although, the inverted index algorithm is implemented 
serially, the MapReduce implementation was unsuccessful. Thus, no runtimes are indicated for 
this algorithm. It is possible to measure the runtime using a serial inverted index using 
\textit{File1ForLab3.txt}. This would be impossible for \textit{File2ForLab3.txt} due to its 
size. Thus, the MapReduce implementation of the inverted index would have been capable of 
handling the size of \textit{File2ForLab3.txt}. 
\section{Conclusion}
The MapReduce solution of the word count, top-K query and inverted index problems is 
presented. MapReduce decomposes large datasets and divides their reading and processing 
between processing units. The MapReduce functionality of the Phoenix framework is utilised 
in the solution. The word count algorithm of the large dataset takes longer than that of the 
small dataset. The top 10 and 20 queries are determined in relatively similar times for both 
datasets. Although a serial inverted index algorith is implemented, the MapReduce algorithm 
was unsuccessful. No running time tests are performed due to this. 
 
\bibliographystyle{IEEEtran}
\bibliography{references.bib}
  Recompile
1
Could not connect to the reCAPTCHA service. Please check your internet connection and reload to get a reCAPTCHA challenge.